# -*- coding: utf-8 -*-
"""CIFAR-10 SimpleNet Data Aug Parameter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YGklQ971c5nNad5pZwdYVu2JvDSrxqiW

    @article{hasanpour2016lets,
  title={Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures},
  author={Hasanpour, Seyyed Hossein and Rouhani, Mohammad and Fayyaz, Mohsen and Sabokrou, Mohammad},
  journal={arXiv preprint arXiv:1608.06037},
  year={2016}
}
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf

from tensorflow.keras import layers
from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D
from tensorflow import keras



def get_CNN():
    inputs = keras.Input(shape=(32,32,3))
    #1st layer
    x = layers.Conv2D(64,3,padding='same',kernel_initializer='he_uniform')(inputs)
    x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
    x = layers.Activation('relu')(x)
    x = layers.Dropout(0.2)(x)

    #2nd, 3rd, 4th layer w non-overlapping maxpooling
    x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
    x = layers.BatchNormalization(axis=-1, momentum=0.095)(x)
    x = layers.Activation('relu')(x)
    x = layers.Dropout(0.2)(x)

    x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
    x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
    x = layers.Activation('relu')(x)
    x = layers.Dropout(0.2)(x)

    x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
    x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
    x = layers.Activation('relu')(x)

    x = layers.MaxPooling2D(pool_size=2,strides=2)(x)

    #5th, 6th layer
    x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
    x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
    x = layers.Activation('relu')(x)
    x = layers.Dropout(0.2)(x)

    x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
    x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
    x = layers.Activation('relu')(x)
    x = layers.Dropout(0.2)(x)

    #7th layer w non-overlapping maxpooling
    x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
    x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
    x = layers.Activation('relu')(x)
    x = layers.Dropout(0.2)(x)

    x = layers.MaxPooling2D(pool_size=2,strides=2)(x)

    #8th, 9th layer w non-overlapping maxpooling
    x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
    x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
    x = layers.Activation('relu')(x)
    x = layers.Dropout(0.2)(x)

    x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
    x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
    x = layers.Activation('relu')(x)
    x = layers.Dropout(0.2)(x)

    x = layers.MaxPooling2D(pool_size=2,strides=2)(x)

    #10th, 11th, 12th layer w non-overlapping maxpooling
    x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
    x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
    x = layers.Activation('relu')(x)
    x = layers.Dropout(0.2)(x)

    x = layers.Conv2D(128,1,kernel_initializer='he_uniform')(x)
    x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
    x = layers.Activation('relu')(x)
    x = layers.Dropout(0.2)(x)

    x = layers.Conv2D(128,1,kernel_initializer='he_uniform')(x)
    x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
    x = layers.Activation('relu')(x)
    x = layers.Dropout(0.2)(x)

    x = layers.MaxPooling2D(pool_size=2,strides=2)(x)

    #13th layer
    x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)

    #flatten
    x = layers.Flatten()(x)

    outputs = layers.Dense(10, activation='softmax')(x)

    model = keras.Model(inputs=inputs,outputs=outputs,name='simplenet')

    
    model.compile(loss='categorical_crossentropy',
                optimizer='adam',
                metrics=['accuracy'])
    return model



