# -*- coding: utf-8 -*-
"""CIFAR-10 SimpleNet Hyperas Parameter Optimization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_qfRxCW29tRvtjYemDigU1KDT8VhFtxF

    @article{hasanpour2016lets,
  title={Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures},
  author={Hasanpour, Seyyed Hossein and Rouhani, Mohammad and Fayyaz, Mohsen and Sabokrou, Mohammad},
  journal={arXiv preprint arXiv:1608.06037},
  year={2016}
}

"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

from tensorflow.keras.datasets import cifar10
from tensorflow.keras import layers
from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D
from tensorflow import keras
from tensorflow.keras.utils import to_categorical
import datetime, os

from hyperopt import Trials, STATUS_OK, tpe
from hyperas import optim
from hyperas.distributions import choice, uniform

def data ():
    """
    Data returning function 
    returns:
    cifar-10 dataset (X_train, Y_train, X_test, Y_test)
    """
    (X_train_orig,Y_train_orig),(X_test_orig,Y_test_orig) = cifar10.load_data()
    #normalize
    X_train = X_train_orig/255.
    X_test = X_test_orig/255.
  
  
    #one-hot encoding
    Y_train = to_categorical(Y_train_orig, 10)
    Y_test = to_categorical(Y_test_orig, 10)
    return X_train, Y_train, X_test, Y_test

def model(X_train, Y_train, X_test, Y_test):
  
  inputs = keras.Input(shape=(32,32,3))
  #1st layer
  x = layers.Conv2D(64,3,padding='same',kernel_initializer='he_uniform')(inputs)
  x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
  x = layers.Activation('relu')(x)
  x = layers.Dropout(0.2)(x)

  #2nd, 3rd, 4th layer w non-overlapping maxpooling
  x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
  x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
  x = layers.Activation('relu')(x)
  x = layers.Dropout(0.2)(x)

  x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
  x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
  x = layers.Activation('relu')(x)
  x = layers.Dropout(0.2)(x)

  x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
  x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
  x = layers.Activation('relu')(x)

  x = layers.MaxPooling2D(pool_size=2,strides=2)(x)

  #5th, 6th layer
  x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
  x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
  x = layers.Activation('relu')(x)
  x = layers.Dropout(0.2)(x)

  x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
  x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
  x = layers.Activation('relu')(x)
  x = layers.Dropout(0.2)(x)

  #7th layer w non-overlapping maxpooling
  x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
  x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
  x = layers.Activation('relu')(x)
  x = layers.Dropout(0.2)(x)

  x = layers.MaxPooling2D(pool_size=2,strides=2)(x)

  #8th, 9th layer w non-overlapping maxpooling
  x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
  x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
  x = layers.Activation('relu')(x)
  x = layers.Dropout(0.2)(x)

  x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
  x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
  x = layers.Activation('relu')(x)
  x = layers.Dropout(0.2)(x)

  x = layers.MaxPooling2D(pool_size=2,strides=2)(x)

  #10th, 11th, 12th layer w non-overlapping maxpooling
  x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)
  x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
  x = layers.Activation('relu')(x)
  x = layers.Dropout(0.2)(x)

  x = layers.Conv2D(128,1,kernel_initializer='he_uniform')(x)
  x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
  x = layers.Activation('relu')(x)
  x = layers.Dropout(0.2)(x)

  x = layers.Conv2D(128,1,kernel_initializer='he_uniform')(x)
  x = layers.BatchNormalization(axis=-1, momentum=0.95)(x)
  x = layers.Activation('relu')(x)
  x = layers.Dropout(0.2)(x)

  x = layers.MaxPooling2D(pool_size=2,strides=2)(x)

  #13th layer
  x = layers.Conv2D(128,3,padding='same',kernel_initializer='he_uniform')(x)

  #flatten
  x = layers.Flatten()(x)

  outputs = layers.Dense(10, activation='softmax')(x)

  model = keras.Model(inputs=inputs,outputs=outputs,name='simplenet')
  model.compile(loss='categorical_crossentropy', optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},metrics=['accuracy'])
  model.fit(X_train, Y_train, batch_size={{choice([32,64,128])}},epochs=2,validation_split=0.2)
  score, acc = model.evaluate(X_test, Y_test, verbose=0)
  print('Test accuracy:', acc)
  return {'loss': -acc, 'status': STATUS_OK, 'model': model}

# See: https://stackoverflow.com/questions/49920031/get-the-path-of-the-notebook-on-google-colab
# Install the PyDrive wrapper & import libraries.
#!pip install -U -q PyDrive
#from pydrive.auth import GoogleAuth
#from pydrive.drive import GoogleDrive
#from google.colab import auth
#from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client.
#auth.authenticate_user()
#gauth = GoogleAuth()
#gauth.credentials = GoogleCredentials.get_application_default()
#drive = GoogleDrive(gauth)

# Copy/download the file
#fid = drive.ListFile({'q':"title='CIFAR-10 SimpleNet Hyperas Parameter Optimization.ipynb'"}).GetList()[0]['id']
#f = drive.CreateFile({'id': fid})
#f.GetContentFile('CIFAR-10 SimpleNet Hyperas Parameter Optimization.ipynb')

if __name__ == '__main__':
    best_run, best_model = optim.minimize(model=model,
                                          data=data,
                                          algo=tpe.suggest,
                                          max_evals=5,
                                          trials=Trials())
    X_train, Y_train, X_test, Y_test = data()
    print("Evalutation of best performing model:")
    print(best_model.evaluate(X_test, Y_test))
    print("Best performing model chosen hyper-parameters:")
    print(best_run)


